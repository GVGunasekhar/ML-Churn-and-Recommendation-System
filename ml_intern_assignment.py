# -*- coding: utf-8 -*-
"""ML-INTERN-ASSIGNMENT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yU7rLwh8lM_W4AkqljxqZgj3SYKRK5S5

#Predict Customer Churn and Build Insights for Retention

Tasks:-

**1. Exploratory Data Analysis (EDA)**

a.Load Dataset
"""

import pandas as pd
import numpy as np

# Load the dataset
file_path = "/content/Assignment_Data - ML_Intern_Assignment_Data.csv.csv"
df = pd.read_csv(file_path)

# Inspect structure
print("Dataset Shape:", df.shape)
print("\nDataset Info:")
print(df.info())

# Display first few rows
print("\nSample Data:")
print(df.head())

# Summary statistics
print("\nSummary Statistics:")
print(df.describe())

"""b. Identify Missing/Null Values"""

# Check for missing values
missing_values = df.isnull().sum()
print("\nMissing Values:")
print(missing_values)

# Handling missing values
# Option 1: Drop rows with missing values
# df.dropna(inplace=True)

# Option 2: Impute missing values (example for numerical columns)
# df['column_name'].fillna(df['column_name'].mean(), inplace=True)

# Confirm missing values are handled
print("\nAfter Handling Missing Values:")
print(df.isnull().sum())

"""c.Univariate Analysis"""

import matplotlib.pyplot as plt
import seaborn as sns

# Example: Distribution of 'Churn' variable
sns.countplot(data=df, x='churn') # Changed 'Churn' to 'churn'
plt.title('Distribution of Churn')
plt.show()

# Example: Distribution of numerical features (e.g., tenure, MonthlyCharges)
numerical_cols = ['tenure', 'monthlycharges', 'totalcharges'] # Changed column names to lowercase

# Convert column names to lowercase to avoid case sensitivity issues
df.columns = df.columns.str.lower()

for col in numerical_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(df[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

# Box plot for outliers
for col in numerical_cols:
    plt.figure(figsize=(8, 4))
    sns.boxplot(data=df, x='churn', y=col) # Changed 'Churn' to 'churn'
    plt.title(f'Box Plot of {col} by Churn')
    plt.show()

"""d.Bivariate Analysis"""

# Correlation matrix and heatmap
# Include numeric_only=True to consider only numerical columns for correlation
correlation_matrix = df.corr(numeric_only=True)

plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

# Scatter plots for key relationships
plt.figure(figsize=(8, 4))
sns.scatterplot(data=df, x='tenure', y='monthlycharges', hue='churn')
plt.title('Tenure vs Monthly Charges by Churn')
plt.show()

plt.figure(figsize=(8, 4))
sns.scatterplot(data=df, x='totalcharges', y='monthlycharges', hue='churn')
plt.title('Total Charges vs Monthly Charges by Churn')
plt.show()

# Grouped bar chart
# Use a list instead of a tuple to select multiple columns
grouped_data = df.groupby('churn')[['tenure', 'monthlycharges']].mean().reset_index()

grouped_data.plot(
    x='churn',
    kind='bar',
    figsize=(8, 4),
    title='Average Tenure and Monthly Charges by Churn'
)
plt.show()

"""e.Visualizations"""

# Pie chart for customer segments
# Changed 'Churn' to 'churn' to match the lowercase column name
churn_counts = df['churn'].value_counts()
churn_labels = churn_counts.index

plt.figure(figsize=(8, 6))
plt.pie(churn_counts, labels=churn_labels, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'salmon'])
plt.title('Customer Churn Distribution')
plt.show()

# KDE Plot for overlapping distributions
plt.figure(figsize=(8, 6))
# Changed 'Churn' to 'churn' to match the lowercase column name
sns.kdeplot(data=df[df['churn'] == 'Yes'], x='monthlycharges', fill=True, label='Churn = Yes')
sns.kdeplot(data=df[df['churn'] == 'No'], x='monthlycharges', fill=True, label='Churn = No')
plt.title('KDE Plot of Monthly Charges by Churn Status')
plt.legend()
plt.show()

"""**2. Feature Engineering**

a.Create New Features
"""

# Handle potential division by zero or missing values in Tenure
df['tenure'] = df['tenure'].replace(0, np.nan)  # Changed 'Tenure' to 'tenure'

# AvgMonthlySpend: TotalCharges / Tenure
df['AvgMonthlySpend'] = df['totalcharges'] / df['tenure']  # Changed 'TotalCharges' to 'totalcharges' and 'Tenure' to 'tenure'

# EngagementScore: Example based on MonthlyCharges and Tenure
# Higher tenure and higher monthly charges => Higher engagement
df['EngagementScore'] = df['tenure'] * df['monthlycharges']  # Changed 'Tenure' to 'tenure' and 'MonthlyCharges' to 'monthlycharges'

# Check new features
print(df[['AvgMonthlySpend', 'EngagementScore']].head())

"""b.Feature Encoding"""

from sklearn.preprocessing import LabelEncoder

# Apply Label Encoding for binary categorical variables
# Changed 'Churn' to 'churn' to match the lowercase column name
binary_cols = ['churn']  # Example
for col in binary_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])

# One-Hot Encoding for multi-class categorical variables
# Changed column names to lowercase to match the DataFrame
# Make sure these columns exist in your DataFrame
categorical_cols = ['contract', 'internetservice', 'paymentmethod']
# Check if the columns exist in the DataFrame before applying get_dummies
for col in categorical_cols:
    if col not in df.columns:
        print(f"Warning: Column '{col}' not found in DataFrame. Skipping one-hot encoding for this column.")
    else:
        df = pd.get_dummies(df, columns=[col], drop_first=True)  # Encode one column at a time

# Verify encoded columns
print("\nColumns after encoding:")
print(df.columns)

"""c. Scaling Numerical Variables"""

from sklearn.preprocessing import StandardScaler, MinMaxScaler

# Select numerical columns, ensuring they match the case in your DataFrame
numerical_cols = ['tenure', 'monthlycharges', 'totalcharges', 'AvgMonthlySpend', 'EngagementScore']

# Standardization (mean=0, std=1)
scaler = StandardScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

# Alternatively, Min-Max Scaling (range [0, 1])
# scaler = MinMaxScaler()
# df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

# Verify scaled values
print("\nScaled Numerical Features:")
print(df[numerical_cols].head())

"""Final DataFrame Check"""

# Final check of the DataFrame
print("\nFinal DataFrame Shape:", df.shape)
print(df.head())

"""**3. Predictive Modeling**

a.Split the Dataset

Use train_test_split to divide the data into training and testing sets.
"""

# Define features (X) and target (y)
X = df.drop(columns=['churn'])  # Changed 'Churn' to 'churn' to match the lowercase column name
y = df['churn']  # Changed 'Churn' to 'churn' to match the lowercase column name

# Split into training (70%) and testing (30%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print(f"Training Set Shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Testing Set Shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""b. Train Models

Train Logistic Regression, Decision Trees, and Random Forest models.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Ensure all categorical variables are encoded
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
categorical_cols.remove('customerid')  # Exclude 'customerid' from encoding

# Define features (X) and target (y)
X = df.drop(columns=['churn', 'customerid'])  # Remove target and irrelevant columns
y = df['churn']  # Target variable

# Define a preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', StandardScaler(), X.select_dtypes(include=['int64', 'float64']).columns.tolist())
    ]
)

# Split into training (70%) and testing (30%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print(f"Training Set Shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Testing Set Shape: X_test={X_test.shape}, y_test={y_test.shape}")

# Initialize models
models = {
    "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42)
}

# Train models using cross-validation (5-fold)
for name, model in models.items():
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')
    print(f"{name} CV Accuracy: {scores.mean():.4f} Â± {scores.std():.4f}")

"""c. Evaluate Models"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
import pandas as pd

# Preprocessing pipeline
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', StandardScaler(), numerical_cols)
    ]
)

# Train and evaluate each model with pipelines
evaluation_metrics = []
for name, model in models.items():
    # Create a pipeline with preprocessing and the model
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])

    # Train the pipeline
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    evaluation_metrics.append([name, accuracy, precision, recall, f1])

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    print(f"\n{name} Confusion Matrix:\n{cm}")

# Summarize metrics
metrics_df = pd.DataFrame(evaluation_metrics, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])
print("\nModel Performance Summary:")
print(metrics_df)

"""d.Visualize Confusion Matrices"""

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Get the best-performing model based on F1-Score
best_model_name = metrics_df.sort_values(by='F1-Score', ascending=False).iloc[0]['Model']
best_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', models[best_model_name])
])

# Train the pipeline on the full training set
best_pipeline.fit(X_train, y_train)

# Predict using the pipeline
y_pred = best_pipeline.predict(X_test)

# Plot confusion matrix
disp = ConfusionMatrixDisplay.from_estimator(
    best_pipeline,
    X_test,
    y_test,
    display_labels=best_pipeline.named_steps['model'].classes_,
    cmap='Blues'
)
plt.title(f"Confusion Matrix for {best_model_name}")
plt.show()

"""**4. Model Interpretation**

a.Feature Importance (Using Random Forest)
"""

from sklearn.preprocessing import LabelEncoder
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier

# Identify categorical columns (assuming you have some columns with categorical data)
categorical_cols = X_train.select_dtypes(include=['object']).columns

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Encode categorical features
for col in categorical_cols:
    X_train[col] = label_encoder.fit_transform(X_train[col])
    X_test[col] = label_encoder.transform(X_test[col])  # Apply same encoding to test data

# Train Random Forest on the full training data
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Extract feature importance
feature_importance = rf_model.feature_importances_
features = X_train.columns

# Plot feature importance
sorted_idx = np.argsort(feature_importance)[::-1]  # Sort in descending order
plt.figure(figsize=(10, 6))
plt.bar(range(len(features)), feature_importance[sorted_idx], align='center')
plt.xticks(range(len(features)), features[sorted_idx], rotation=90)
plt.title("Feature Importance (Random Forest)")
plt.ylabel("Importance Score")
plt.show()

"""b.SHAP for Detailed Interpretability"""

# Install SHAP if not already installed
!pip install shap

import shap
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

# Encode categorical features
categorical_cols = X_train.select_dtypes(include=['object']).columns
label_encoder = LabelEncoder()

for col in categorical_cols:
    X_train[col] = label_encoder.fit_transform(X_train[col])
    X_test[col] = label_encoder.transform(X_test[col])

# Train Random Forest model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# SHAP Explainer
explainer = shap.TreeExplainer(rf_model)

# Get SHAP values for all classes
shap_values = explainer.shap_values(X_train)

# If it's a binary classification, shap_values[1] corresponds to the positive class
# For multi-class, shap_values will contain one array per class.
if isinstance(shap_values, list):  # Multi-class or binary classification
    if len(shap_values) == 2:  # Binary classification
        shap_values_to_plot = shap_values[1]  # Positive class
    else:  # Multi-class classification
        # Select the class index you'd like to visualize, for example class 0
        shap_values_to_plot = shap_values[0]  # First class (you can adjust this)
else:
    shap_values_to_plot = shap_values  # For regression tasks, this is a single array

# SHAP Summary Plot (Bar Plot)
shap.summary_plot(shap_values_to_plot, X_train, plot_type="bar")

# Detailed Insights (Interactive Plot)
shap.initjs()  # Initialize JavaScript visualization (required for interactive plots)
shap.summary_plot(shap_values_to_plot, X_train)  # Detailed summary plot

"""**5. Recommendation Engine**

a.Installing and Importing Required Libraries
"""

!pip install scikit-surprise
!pip install lightfm

"""b.Building User-Based Collaborative Filtering Model with Surprise"""

import pandas as pd
from surprise import Reader, Dataset, KNNBasic
from surprise.model_selection import train_test_split
from surprise import accuracy

# Load the data (Example: customer-product interaction matrix)
# Example data in the form: [user, product, rating]
data = [
    ('user1', 'product1', 5),
    ('user1', 'product2', 3),
    ('user2', 'product1', 4),
    ('user2', 'product3', 2),
    ('user3', 'product2', 4),
    ('user3', 'product3', 5),
    # Add more rows as needed
]

# Create a DataFrame
df = pd.DataFrame(data, columns=['user', 'product', 'rating'])

# Define the format of the data
reader = Reader(rating_scale=(1, 5))  # Rating scale from 1 to 5
dataset = Dataset.load_from_df(df[['user', 'product', 'rating']], reader)

# Split the data into training and test sets
trainset, testset = train_test_split(dataset, test_size=0.2)

# Build the collaborative filtering model (User-based)
sim_options = {
    'name': 'cosine',
    'user_based': True,  # User-based collaborative filtering
}

model = KNNBasic(sim_options=sim_options)

# Train the model
model.fit(trainset)

# Test the model
predictions = model.test(testset)

# Compute and print RMSE (Root Mean Squared Error)
rmse = accuracy.rmse(predictions)
print(f"RMSE: {rmse}")

# Make predictions for a specific user (e.g., recommend products for 'user1')
user_id = 'user1'
product_list = ['product1', 'product2', 'product3']
for product in product_list:
    pred = model.predict(user_id, product)
    print(f"Prediction for {user_id} on {product}: {pred.est}")

"""c. Hybrid Recommendation Systems"""

import numpy as np
from lightfm import LightFM
from lightfm.datasets import fetch_movielens

# Fetch the Movielens dataset for demonstration purposes
data = fetch_movielens()

# Build the model (Hybrid approach)
model = LightFM(loss='warp')  # 'warp' is an effective approach for hybrid filtering
model.fit(data['train'], epochs=30, num_threads=2)

# Get recommendations for a specific user (e.g., User 1)
scores = model.predict(0, np.arange(data['train'].shape[1]))

# Sort the scores in descending order to get top items
top_items = np.argsort(scores)[::-1]

# Print the top 5 recommended items for User 1
print("Top 5 recommendations for User 1:")
for item in top_items[:5]:
    print(item)